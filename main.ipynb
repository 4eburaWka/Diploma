{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import timm\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoise(object):\n",
    "    def __init__(self, noise_level):\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_tensor = transforms.functional.to_tensor(img)\n",
    "        noise = torch.rand_like(img_tensor) * self.noise_level\n",
    "        noisy_img = img_tensor + noise\n",
    "        return transforms.functional.to_pil_image(noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "COLOR_DEVIATION = 0.01\n",
    "image_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size=SIZE),\n",
    "        AddNoise(0.01),\n",
    "        transforms.ColorJitter(brightness=(1.0-COLOR_DEVIATION,1.0+COLOR_DEVIATION),contrast=(1.0-COLOR_DEVIATION,1.0+COLOR_DEVIATION),saturation=(1.0-COLOR_DEVIATION,1.0+COLOR_DEVIATION),hue=(-1*COLOR_DEVIATION,COLOR_DEVIATION)),\n",
    "        transforms.RandomRotation(degrees=0),\n",
    "        transforms.RandomAffine(degrees=0),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize(size=SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'eyepac-light-v2-512-jpg/'\n",
    "train_directory = root + 'train'\n",
    "test_directory = root + 'test'\n",
    "validation_directory = root + 'validation'\n",
    "\n",
    "# batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    'validation': datasets.ImageFolder(root=validation_directory, transform=image_transforms['validation']),\n",
    "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_size = len(data['train'])\n",
    "validation_data_size = len(data['validation'])\n",
    "test_data_size = len(data['test'])\n",
    "\n",
    "train_data = DataLoader(data['train'], batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "validation_data = DataLoader(data['validation'], batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_data = DataLoader(data['test'], batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name: str):\n",
    "    match model_name:\n",
    "        case \"mobilenetv3-large\": # 8 min/epoch\n",
    "            model_ft = models.mobilenet_v3_large(weights=torchvision.models.MobileNet_V3_Large_Weights.DEFAULT, progress=True)\n",
    "            model_ft.classifier[-1] = nn.Linear(1280, 2)\n",
    "        case \"mobilenetv3-small\": # 8\n",
    "            model_ft = models.mobilenet_v3_small(weights=torchvision.models.MobileNet_V3_Small_Weights.DEFAULT, progress=True)\n",
    "            model_ft.classifier[-1] = nn.Linear(1024, 2)\n",
    "        case \"efficientnet-b0\": # 8\n",
    "            model_ft = models.efficientnet_b0(weights='IMAGENET1K_V1', progress=True)\n",
    "            model_ft.classifier[-1] = nn.Linear(1280, 2)\n",
    "        case \"resnet18\": # 8\n",
    "            model_ft = models.resnet18(weights='IMAGENET1K_V1', progress=True)\n",
    "            model_ft.fc = nn.Linear(512, 2)\n",
    "        case \"efficientnet-b3\":  # 20\n",
    "            model_ft = models.efficientnet_b3(weights='IMAGENET1K_V1', progress=True)\n",
    "            model_ft.classifier[-1] = nn.Linear(1536, 2)\n",
    "        case \"squeezenet\": # 6.3\n",
    "            model_ft = models.squeezenet1_0(weights='IMAGENET1K_V1', progress=True)\n",
    "            model_ft.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1,1), stride=(1,1))\n",
    "            model_ft.num_classes = 2\n",
    "        case \"vit-tiny\": # 2.3\n",
    "            model_ft = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=2)\n",
    "        case \"densenet121\":\n",
    "            model_ft = models.densenet121(weights='IMAGENET1K_V1', progress=True)\n",
    "            model_ft.classifier = nn.Linear(1024, 2)\n",
    "        case \"convnext-tiny\": # 18\n",
    "            model_ft = timm.create_model('convnext_tiny', pretrained=True, num_classes=2)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    train_metrics = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Create a progress bar for the epoch\n",
    "        epoch_progress = tqdm(total=len(train_data), desc=f'Epoch {epoch + 1}/{num_epochs}', position=0, leave=False)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            all_labels, all_preds = [], []\n",
    "\n",
    "            # Set model mode\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                dataloader = train_data\n",
    "            else:\n",
    "                model.eval()\n",
    "                dataloader = validation_data\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0) / len(data[phase])\n",
    "                running_corrects += torch.sum(preds == labels.data).double() / len(data[phase])\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                # Update progress bar\n",
    "                epoch_progress.set_postfix(phase=phase, loss=loss.item(), acc=running_corrects.item())\n",
    "                epoch_progress.update()\n",
    "\n",
    "            # Adjust learning rate\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss\n",
    "            epoch_acc = running_corrects\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "            epoch_auc = roc_auc_score(all_labels, all_preds)\n",
    "            epoch_vram = torch.cuda.memory_allocated() / 1024**2\n",
    "            \n",
    "            train_metrics.append({'Loss': epoch_loss.real, 'Acc': epoch_acc.item(), 'F1': epoch_f1, 'Auc': epoch_auc, 'VRAM': epoch_vram})\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Update best accuracy\n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        epoch_progress.close()\n",
    "\n",
    "    # Test the model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    model.eval()\n",
    "    test_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_data:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = test_corrects.double() / test_data_size\n",
    "    print('Test Accuracy: {:.4f}'.format(test_acc))\n",
    "\n",
    "    return model, train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  6955906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 2004it [04:13, 10.50it/s, acc=0.0247, loss=0.61, phase=validation]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7071 Acc: 0.5152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 1.0868 Acc: 0.5338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 2003it [04:35, 12.50it/s, acc=0.0208, loss=0.691, phase=validation]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6953 Acc: 0.5164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.7676 Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  40%|████      | 808/2000 [01:41<02:29,  7.95it/s, acc=0.204, loss=0.706, phase=train] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, total_params)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m model_ft, train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m train_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAcc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVRAM\u001b[39m\u001b[38;5;124m'\u001b[39m], data\u001b[38;5;241m=\u001b[39mtrain_metrics)\n",
      "Cell \u001b[1;32mIn[30], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     39\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data[phase])\n",
      "File \u001b[1;32md:\\PROJECTS\\Diploma\\venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PROJECTS\\Diploma\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PROJECTS\\Diploma\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_names = [\"mobilenetv3-large\", \"mobilenetv3-small\", \"efficientnet-b0\", \"resnet18\",\n",
    "                \"efficientnet-b3\", \"squeezenet\", \"densenet121\", \"vit-tiny\", \"convnext-tiny\"]\n",
    "model_name = models_names[6]\n",
    "\n",
    "# load pretrained model\n",
    "model_ft = get_model(model_name)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 2 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "# Calculate the number of parameters\n",
    "total_params = sum(p.numel() for p in model_ft.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "\n",
    "# Train the model\n",
    "model_ft, train_metrics = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)\n",
    "train_results = pd.DataFrame(columns=['Loss', 'Acc', 'F1', 'Auc', 'VRAM'], data=train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), f'{model_name}_weiths.pth')\n",
    "train_results.to_csv(f\"{model_name}_train_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
